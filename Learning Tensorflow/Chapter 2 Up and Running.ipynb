{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n",
      "Tensor(\"add_8:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "h = tf.constant(\"Hello\")\n",
    "w = tf.constant(\" World!\")\n",
    "hw = h + w\n",
    "with tf.Session() as sess:\n",
    "    ans = sess.run(hw)\n",
    "print (ans)\n",
    "print(hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ph = 'Hello'\n",
    "pw = \" World!\"\n",
    "phw = h+w\n",
    "\n",
    "print (hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably not what you expected!\n",
    "\n",
    "- In the next chapter we explain the computation graph model of TensorFlow in detail, at which point this output will become completely clear. \n",
    "\n",
    "- The key idea behind computation graphs in TensorFlow is:  \n",
    "       \n",
    "   - that we first define what computations should take place,\n",
    "   - and then trigger the computation in an external mechanism. \n",
    "\n",
    "- Thus, the Tensor‐ Flow line of code: \n",
    "    \n",
    "        hw = h+w\n",
    "<b> does not compute the sum of h and w but rather adds the summation operation to a graph of computations to be done later </b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> What does the Session object do? </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acts as an interface to the external TensorFlow computation\n",
    "mechanism, and allows us to run parts of the computation graph we have already defined.\n",
    "\n",
    "Thus the line\n",
    "\n",
    "    ans = sess.run(hw)\n",
    "\n",
    "actually computes hw (the sum of h and w) so that's why we see 'Hello World!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST (Mixed National Institute of Standards and Technology) handwritten\n",
    "digits dataset is one of the most researched datasets in image processing and machine\n",
    "learning, and has played an important role in the development of artificial neural networks\n",
    "(now generally referred to as deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> What will we be doing then? </u>\n",
    "\n",
    "Classifying handwritten digits using a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> What does learning in this model consist of? </u>\n",
    "\n",
    "finding weights that tell us how to accumulate evidence\n",
    "for the existence of each of the digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We <b> will not </b> be using spatial info in the pixel layout in the image so we will unroll the image pixels as a single long vector denoted, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x*w^0 = sum( xi * wi^0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will be the evidence for the image containing the digit 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means:\n",
    "    \n",
    "- we sum up the pixel values, \n",
    "- each multiplied by a weight which we think of as the importance of this pixel in the overall evidence for the digit zero being in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w sub 38, super 0: will be \n",
    "- a large postiive number if the 38th pixel having a high intensity points strongly to the digit being a zero\n",
    "- a strong negative number if highintensity values in this position occur mostly in other digits\n",
    "- and zero if the intensity value of the 38th pixel tells us nothing about whether or not this digit is a zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of learning a classifier is almost always to evaluate new examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, this means that \n",
    "- we would like to be able to tell what digit is written in a new image we have not seen in our training data. \n",
    "- In order to do this, we start by summing up the evidence for each of the 10 possible digits (i.e., computing xW). \n",
    "- The final assignment will be the digit that “wins” by accumulating the most evidence:\n",
    "\n",
    "        digit = argmax(xW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2-2. Classifying MNIST handwritten digits with softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-cd188b39a6e0>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-17-cd188b39a6e0>:13: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Accuracy: 91.15%\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=y_pred, labels=y_true))\n",
    "\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    for _ in range(NUM_STEPS):\n",
    "        batch_xs, batch_ys = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict={x: batch_xs, y_true: batch_ys})\n",
    "\n",
    "    # Test\n",
    "    ans = sess.run(accuracy, feed_dict={x: data.test.images,\n",
    "                                y_true: data.test.labels})\n",
    "\n",
    "print (\"Accuracy: {:.4}%\".format(ans*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
