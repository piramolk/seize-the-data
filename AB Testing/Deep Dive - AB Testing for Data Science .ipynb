{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80d7ad3",
   "metadata": {},
   "source": [
    "# About\n",
    "* Objective\n",
    "    * concise guide and execution of A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beefbc0",
   "metadata": {},
   "source": [
    "# 1. Intro\n",
    "\n",
    "## What is A/B testing?\n",
    "* A/B testing is a basic randomized control experiment. It is a way to compare the two versions of a variable to find out which performs better in a controlled environment.\n",
    "* e.g. you want to increase web traffic to your website\n",
    "    * You can use random experiments and see how they affect the web traffic (very broad, takes a long time)\n",
    "    * You can apply scientific an statistical methods -> A/B testing\n",
    "    \n",
    "    ### Why is it called A/B testing?\n",
    "    * In the scenario above, we divide the the experiments into two parts\n",
    "        * A is our control so it will remain the same\n",
    "        * B is where we make signficant changes\n",
    "    * It then becomes a hypothesis testing problem and we make decisions that estimate population parameters based on sample statistics\n",
    "        * Population: All the users going to your website\n",
    "        * Sample: The number of customers that participated in the test\n",
    " \n",
    "--- \n",
    "## Hypothesis Testing Primer [ref 2]\n",
    "* Hypothesis testing underlies A/B testing so let's do a quick recap of the major concepts\n",
    "\n",
    "### Example: NSFG data\n",
    "* NSFG study (National survery of family growth)\n",
    "    * \\information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and men's and women's health. \n",
    "    * The survey results are used ... to plan health services and health education programs, and to do statistical studies of families, fertility, and health.\"\n",
    "    * We will use data collected by this survey to investigate <b>whether first-born babies tend to come late, and other questions</b>\n",
    "* What we're trying to suss out is if an effect i.e. the observed differences between first babies and others, is a <b> real difference</b> or might appear in the sample </b> by chance</b>\n",
    "    * A few ways we can formulate this Q\n",
    "        * Fisher null hypothesis testing\n",
    "        * Neyman-Pearson decision theory\n",
    "        * Bayesian inference\n",
    "        \n",
    "### Classical Hypothesis testing\n",
    "* The goal of classical hypothesis testing is to answer the question, <b> Given a sample and an apparent e ect, what is the probability of seeing such an effect by chance?</b> \n",
    "* Here's how we answer that question\n",
    "    1. Quantify the size of apparent effect by choosing a <b> test statistic </b>\n",
    "        * in the NSFG data, the apparent effect is a difference in pregnancy length between first babies and others, so test statistic-> difference in means between the two groups\n",
    "    2. Define the <b>null hypothesis </b>\n",
    "        * null hypothesis: a model of the system based on the assumption that the apparent effect is not real\n",
    "        * In the NSFG data, the null hypothesis is that there is no difference between first babies and others i.e. that pregnancy lengths for both groups have the same distribution\n",
    "     3. Compute a p-value\n",
    "         * p-value: the probability of seeing the apparent e ect if the null hypothesis is true.\n",
    "         * we would compute the <b>actual difference in means</b>, then compute the probability of seeing a difference as big, or bigger, under the null hypothesis.\n",
    "     4. Interpret the result\n",
    "         * If the p-value is low, the effect is said to be statistically signi cant, which means that it is unlikely to have occurred by chance. \n",
    "         * In that case we infer that the e ect is more likely to appear in the larger population.\n",
    "* In plainspeak\n",
    "    * To test a hypothesis like \"This effect is real,\" we assume, temporarily, that it is not. That's the null hypothesis. \n",
    "    * Based on that assumption, we compute the probability of the apparent effect. That's the p-value. \n",
    "    * If the p-value is low, we conclude that the null hypothesis is unlikely to be true.\n",
    "---\n",
    "## Hypothesis Testing and A/B testing\n",
    "1. Null hypothesis\n",
    "    * The null hypothesis is the one that states that sample observations result purely from chance. \n",
    "    * From an A/B test perspective, the null hypothesis states that there is no difference between the control and variant groups. \n",
    "    * It states the default position to be tested or the situation as it is now, i.e. the status quo. \n",
    "    * Here our H0 is <i>”there is no difference in the conversion rate in customers receiving newsletter A and B”.</i>\n",
    "\n",
    "2. Alternative hypothesis\n",
    "    * The alternative hypothesis challenges the null hypothesis and is basically a hypothesis that the researcher believes to be true. \n",
    "    * The alternative hypothesis is what you might hope that your A/B test will prove to be true.\n",
    "    * For example, the Ha is “the conversion rate of newsletter B is higher than those who receive newsletter A“.\n",
    "    \n",
    "----\n",
    "\n",
    "# 2. Create Control Group and Test Group\n",
    "* Once we are ready with our null and alternative hypothesis, the next step is to decide the group of customers that will participate in the test. Here we have two groups – The Control group, and the Test (variant) group.\n",
    "\n",
    "* The Control Group is the one that will receive newsletter A and the Test Group is the one that will receive newsletter B.\n",
    "* For this experiment, we randomly select 1000 customers – 500 each for our Control group and Test group.\n",
    "* <b> Random sampling: </b>\n",
    "    * Randomly selecting the sample from the population\n",
    "    * It is a technique where each sample in a population has an equal chance of being chosen. \n",
    "    * random sampling is important because it eliminates sampling bias\n",
    "* We have to eliminate bias because we want the results of the A/B test to be representative of the entire population rather than the sample itself\n",
    "* <b> Sample size </b>\n",
    "    * It is imperative that we determine the minimum sample size for our a/b test because conducting it\n",
    "    * This is so we can eliminate undercoverage bias -> the bias from sampling too few observations\n",
    "----\n",
    "# 3. Conduct the A/B test and collect the data\n",
    "* If our performance metric that we want to improve is conversion rate:\n",
    "* We can calculate daily conversion rates for both the treatment and the control groups\n",
    "    * the conversion rate in a group on a certain day represents a single data point, the sample size becomes the number of days\n",
    "    * So we will be testing the difference between the mean of daily conversion rates in each group across the testing period.\n",
    "* example data\n",
    "    * run experiment for 1 month\n",
    "    * mean conversion rate for control group: 16%\n",
    "    * mean conversion rate for test group: 19%\n",
    "----\n",
    "# 4. Statistical significance of the Test\n",
    "* To be able to derive a conclusion from these results i.e. the test group is working better than the control group / rejecting our null hypothesis, we need to prove the <b> Statistical Significance </b>\n",
    "\n",
    "## Types of Errors that may occur in hypothesis testing\n",
    "\n",
    "1. Type I error: \n",
    "    * We reject the null hypothesis when it is true. That is we accept the variant B when it is not performing better than A\n",
    "2. Type II error: \n",
    "    * We failed to reject the null hypothesis when it is false. It means we conclude variant B is not good when it performs better than A\n",
    "\n",
    "* <b> To avoid these errors we must calculate the statistical significance of our test </b>\n",
    "\n",
    "### What does 'Statistically Significant' entail?\n",
    "* An experiment is considered to be statistically significant when we have enough evidence to prove that the result we see in the sample also exists in the population.\n",
    "\n",
    "### In our case\n",
    "* We need to determine if the difference between the control version and test version is due to some error/chance or not. \n",
    "* To prove statistical significance, we can use a <b> Two-sample T-test </b>\n",
    "\n",
    "## T-\n",
    "\n",
    "\n",
    "## Two-sample t-test\n",
    "* What is the two-sample t-test?\n",
    "    * The two-sample t-test (also known as the independent samples t-test) is a method used to test whether the unknown population means of two groups are equal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909417c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f01e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f0cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1802fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec43ae4d",
   "metadata": {},
   "source": [
    "# References\n",
    "1.  https://www.analyticsvidhya.com/blog/2020/10/ab-testing-data-science/ \n",
    "2. Allen Downey Think Stats v2, Chapter 9: Hypothesis testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
